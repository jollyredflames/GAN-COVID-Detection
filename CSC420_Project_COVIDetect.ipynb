{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "CSC420_Project_COVIDetect.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jollyredflames/GAN-CXR-Anomaly-Detection/blob/master/CSC420_Project_COVIDetect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGsqJC9iB0TM",
        "colab_type": "text"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YU1cqBJiIkGB",
        "colab_type": "text"
      },
      "source": [
        "The following lines outline the efforts we have taken to repurpose the conditional-adversarial model presented in the pix2pix paper as an anomaly detection model to detect the cases of viral pneumonia from the chest X-ray images. \n",
        "\n",
        "The original model is aimed at a way of style-transfer between pairs of images. For example, the model can be trained on the pairs of aerial images and maps, so in the deployment, it draws maps from aerial images. \n",
        "\n",
        "We have made changes to the original pix2pix model that we discuss here:\n",
        "\n",
        "* The pix2pix model's Generator utilizes the UNet design where skip connections are shared between the encoder/decoder layers. This makes sense in the context of style transfer since we want the network to be able to utilize the information from the input image to come up with the output. However, in the Anomaly Detection context, we want the network to learn to reconstruct CXR images by itself. This means the network will, in theory, do a good job of reconstructing the images it has seen in training (\"normal\" cases) and it will do poorly for the category of images it does not encounter in training (\"abnormal cases\").\n",
        "\n",
        "* Both pix2pix model and our model utilize convolutional autoencoders. However, the pix2pix model shrinks the images a lot before the autoencoder level. However, we want the network to focus on the \"local\" features of images. Therefore, the number of layers in our Generator has been reduced to 4 on each side of the autoencoder. Since the Discriminator is also just a simple convolutional neural network, we have also reduced the number of layers too to reflect the changes for the Generator. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C49tGWSYJoVl",
        "colab_type": "text"
      },
      "source": [
        "# Related Work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBFOKBycJrVr",
        "colab_type": "text"
      },
      "source": [
        "Zhang, J et al [1] has been the inspiration behind the work we have done here. They propose the confidence-aware anomaly detection (CAAD) model that works by a convolutional feature detector model feeding into an anomaly detection module and a confidence prediction module that works together to classify instances of healthy control, viral-pneumonia and non-viral pneumonia. Similar to our proposed model, CAAD utilizes an anomaly detection module that enables it to potentially train in the absence of viral pneumonia CXR cases. We have taken CAAD as the state-of-the-art model with a sweeping 87.47% AUC when the confidence prediction module and the anomaly detection module in it work in tandem. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5xi18m_KD2c",
        "colab_type": "text"
      },
      "source": [
        "# Disscussion "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkC3dLSuKHeV",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oV5UUzdHKIS1",
        "colab_type": "text"
      },
      "source": [
        "# Documented Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6b_tKIoKLei",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moDi2-UoB0TZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "fbb3809b-64f1-4949-961d-788f2599ff68"
      },
      "source": [
        "import torch \n",
        "print('torch version: ', torch.__version__)\n",
        "import torchvision\n",
        "print('torchvision version: ', torchvision.__version__)\n",
        "\n",
        "\n",
        "from torch.utils import data\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import re\n",
        "import zipfile\n",
        "import random\n",
        "import cv2\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.utils import shuffle\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "import glob, inspect, time, math\n",
        "from numpy import savetxt\n",
        "\n",
        "from torch.nn import functional as F\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "torch.autograd.set_detect_anomaly(True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch version:  1.6.0+cu101\n",
            "torchvision version:  0.7.0+cu101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7f718d0fb128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEbaPqKTKSqp",
        "colab_type": "text"
      },
      "source": [
        "## Preparing the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3CJjJsxKWhZ",
        "colab_type": "text"
      },
      "source": [
        "Our current model utlizes a resized version of [CoronaHack](https://www.kaggle.com/praveengovi/coronahack-chest-xraydataset). To use the CXR images in our model, all images have been resized to 256*256. For the model training purposes we utlized Google Colab. The data has been uploaded to Google Drive as a zip file. Here we download the data and unzip it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ai2celgB0Tk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "29344b36-98ac-4a3d-839b-9b8ccc49417b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-z6U35cx4zJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = os.path.join('.', 'drive')\n",
        "data = os.path.join(data, 'My Drive')\n",
        "data_folder = os.path.join(data, 'CSC420_Project')\n",
        "data_zip = os.path.join(data_folder, 'CoronaHack_Resized.zip')\n",
        "\n",
        "zip_ref = zipfile.ZipFile(data_zip, 'r')\n",
        "zip_ref.extractall('/content/CoronaHack')\n",
        "zip_ref.close()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPgb8Ae9kHyV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f75af97a-e425-49f9-e89b-f5e743eef7c1"
      },
      "source": [
        "pic_path = '/content/CoronaHack/CoronaHack_Resized'\n",
        "\n",
        "print(\"Total number of CXR images: {}\".format(len(os.listdir(pic_path))))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of CXR images: 5910\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KmIBlDQK9qk",
        "colab_type": "text"
      },
      "source": [
        "## Model Analytics and Logging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRFF3TMjLCwc",
        "colab_type": "text"
      },
      "source": [
        "The training of neural networks is a costly procedure. We have designed a custome made system of saving model parameters in between training, test snapshots, and train summeries. \n",
        "\n",
        "The block below sets the model analytic paths, create the folders on Google Drive and write the headlines for CSV files that record the test/train snapshots. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR2MCNA3B0Tp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "48900078-6f4c-4dc0-a4c2-a70929c009aa"
      },
      "source": [
        "## Change this based on you model name ##\n",
        "model_name = \"f1-AnomalyDetect\"\n",
        "#####################################\n",
        "\n",
        "def make_dir(path):\n",
        "    try: os.mkdir(path)\n",
        "    except: \n",
        "      pass\n",
        "\n",
        "\n",
        "save_path = F\"/content/drive/My Drive/CSC420_Project/Models/{model_name}\"\n",
        "param_save_path = save_path + \"/params\" \n",
        "snapshots_save_path = save_path + \"/snapshots\" \n",
        "results_path = save_path + \"/results\"\n",
        "\n",
        "OnTrain_summary_path = save_path+\"/01-OnTrain-summary.csv\"\n",
        "OnTestsnapshots_summary_path = save_path+\"/02-OnTest-snapshots-summary.csv\"\n",
        "    \n",
        "\n",
        "\n",
        "make_dir(results_path)\n",
        "make_dir(save_path)\n",
        "make_dir(param_save_path)\n",
        "make_dir(snapshots_save_path)\n",
        "\n",
        "result_list = [\"tr_restoring\", \"pca_latent_ontest\", \"tsne_latent_ontest\"]\n",
        "for result_name in result_list: make_dir(path=os.path.join(results_path, result_name))\n",
        "\n",
        "## Run this once for each model. It will re-write the files ##\n",
        "'''\n",
        "fcsv = open(OnTrain_summary_path, \"w\")\n",
        "fcsv.write(\"epoch,loss_D,loss_G,loss_D_real,loss_D_fake,loss_G_fake,loss_G_L1\\n\")\n",
        "fcsv.close()\n",
        "\n",
        "\n",
        "\n",
        "fcsv = open(OnTestsnapshots_summary_path, \"w\")\n",
        "fcsv.write(\"epoch,G_Normal_loss_Mean,G_AbNormal_loss_Mean,D_Normal_loss_Mean,D_AbNormal_loss_Mean,G_Normal_loss_SD,G_AbNormal_loss_SD,D_Normal_loss_SD,D_AbNormal_loss_SD,G_AUC,D_AUC\\n\")\n",
        "fcsv.close()\n",
        "'''"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfcsv = open(OnTrain_summary_path, \"w\")\\nfcsv.write(\"epoch,loss_D,loss_G,loss_D_real,loss_D_fake,loss_G_fake,loss_G_L1\\n\")\\nfcsv.close()\\n\\n\\n\\nfcsv = open(OnTestsnapshots_summary_path, \"w\")\\nfcsv.write(\"epoch,G_Normal_loss_Mean,G_AbNormal_loss_Mean,D_Normal_loss_Mean,D_AbNormal_loss_Mean,G_Normal_loss_SD,G_AbNormal_loss_SD,D_Normal_loss_SD,D_AbNormal_loss_SD,G_AUC,D_AUC\\n\")\\nfcsv.close()\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5O1k7ZdJB0Tt",
        "colab_type": "text"
      },
      "source": [
        "## Dataset Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yz0m3548LrRF",
        "colab_type": "text"
      },
      "source": [
        "Managing memory allocation is an important part of training any serious neural network. Unlike smaller datasets like MNIST, it is not possible to load the totality of CoronaHack on to the RAM prior to the training. \n",
        "\n",
        "Instead, we have designed and written a custome made dataset class. Out data directory consists of a folder of CXR images, and a CSV file preserving the path and lable information for each image. \n",
        "\n",
        "The Dataset object is responsible for loading train/test images in batches, splitting the data into folds (the design supports kfold cross-validation), and normalizing the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTQvCM3PkRG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = os.path.join(os.getcwd(),  'CoronaHack')\n",
        "\n",
        "data_frame_path = os.path.join(data_path, 'dataset.csv')\n",
        "images_path = os.path.join(data_path, 'CoronaHack_Resized')\n",
        "\n",
        "\n",
        "class Dataset(object):\n",
        "\n",
        "    def __init__(self, normalize=True, normal=['Normal'], ab_normal=['Virus'], n_splits=3, n_exp=0):\n",
        "\n",
        "        print(\"\\nInitializing Dataset...\")\n",
        "\n",
        "        data_frame = pd.read_csv(data_frame_path)\n",
        "\n",
        "        self.data_frame = data_frame\n",
        "        self.normal_labels = normal\n",
        "        self.ab_normal_labels = ab_normal\n",
        "        self.normal_df = shuffle(data_frame.loc[data_frame['label'].isin(normal)], random_state=42)\n",
        "        self.ab_normal_df = shuffle(data_frame.loc[data_frame['label'].isin(ab_normal)], random_state=42)\n",
        "\n",
        "        kf_normal = KFold(n_splits=n_splits, random_state=42)\n",
        "\n",
        "        self.trains = []\n",
        "        self.tests_normals = []\n",
        "        self.tests_ab_normal = []\n",
        "\n",
        "        for train_index, test_index in kf_normal.split(self.normal_df):\n",
        "          self.trains.append(train_index)\n",
        "          self.tests_normals.append(test_index)\n",
        "\n",
        "        for train_index, test_index in kf_normal.split(self.ab_normal_df):\n",
        "          self.tests_ab_normal.append(test_index)\n",
        "\n",
        "        normal_df_train, normal_df_test = self.normal_df.iloc[self.trains[n_exp]], self.normal_df.iloc[self.tests_normals[n_exp]]\n",
        "        ab_normal_df_test = self.ab_normal_df.iloc[self.tests_ab_normal[n_exp]]\n",
        "        \n",
        "        #train_df, test_df = train_test_split(normal_df, test_size=0.33)\n",
        "\n",
        "        self.train_df = normal_df_train\n",
        "        self.test_df = shuffle(pd.concat([ab_normal_df_test, normal_df_test]), random_state=42)\n",
        "        print(\"Running experiment number {} out of {} ----  Train Cases: {} / Test Cases: {} Out of which {} are COVID\"\n",
        "              .format(n_exp, n_splits-1, self.train_df.shape[0], self.test_df.shape[0], ab_normal_df_test.shape[0]))\n",
        "\n",
        "\n",
        "        self.normalize = normalize\n",
        "\n",
        "\n",
        "        self.num_train, self.num_test = self.train_df.shape[0], self.test_df.shape[0]\n",
        "        self.idx_train, self.idx_test = 0, 0\n",
        "\n",
        "        sample_image = cv2.imread(os.path.join(images_path, self.train_df.iloc[0]['cxr_img']))\n",
        "\n",
        "        #self.height = sample_image.shape[0]\n",
        "        #self.width = sample_image.shape[1]\n",
        "\n",
        "        self.height = 256\n",
        "        self.width = 256\n",
        "        self.channel = 3\n",
        "\n",
        "\n",
        "        self.num_class = len(normal) + 1\n",
        "        self.min_val, self.max_val = sample_image.min(), sample_image.max()\n",
        "\n",
        "        print(\"Data Summery\")\n",
        "        print(\"Number of Training Cases: {}\".format(self.num_train))\n",
        "        print(\"Total Number of Test Cases: {}, Abnormal Cases: {}\".format(self.num_test, ab_normal_df_test.shape[0]))\n",
        "        print(\"Shape  Height: %d, Width: %d, Channel: %d\" %(self.height, self.width, self.channel))\n",
        "        print(\"Value  Min: %.3f, Max: %.3f\" %(self.min_val, self.max_val))\n",
        "        print(\"Number of classes:  %d\" %(self.num_class))\n",
        "        print(\"Normalization: %r\" %(self.normalize))\n",
        "        if(self.normalize): print(\"(from %.3f-%.3f to %.3f-%.3f)\" %(self.min_val, self.max_val, 0, 1))\n",
        "\n",
        "\n",
        "    def reset_idx(self): self.idx_train, self.idx_test = 0, 0\n",
        "\n",
        "    def next_train(self, batch_size=1):\n",
        "\n",
        "\n",
        "        start, end = self.idx_train, self.idx_train+batch_size\n",
        "\n",
        "        terminator = False\n",
        "        if(end >= self.num_train):\n",
        "            terminator = True\n",
        "            self.train_df = shuffle(self.train_df)\n",
        "            start = 0\n",
        "            end = batch_size\n",
        "\n",
        "        self.idx_train = end\n",
        "\n",
        "        train_images = np.zeros((batch_size, self.height, self.width, self.channel))\n",
        "        train_labels = np.zeros((batch_size), dtype=int)\n",
        "\n",
        "        for i in range(start, end):\n",
        "            img_path = self.train_df.iloc[i]['cxr_img']\n",
        "            img_path = os.path.join(images_path, img_path)\n",
        "            train_images[i-start] = cv2.imread(img_path)\n",
        "            train_labels[i-start] = 0\n",
        "\n",
        "\n",
        "        train_images = np.ndarray.astype(train_images, np.float32)\n",
        "\n",
        "\n",
        "        if(self.normalize):\n",
        "            min_x, max_x = train_images.min(), train_images.max()\n",
        "            train_images = (train_images - min_x) / (max_x - min_x)\n",
        "\n",
        "        train_images_torch = torch.from_numpy(np.transpose(train_images, (0, 3, 1, 2)))\n",
        "        train_labels_torch = torch.from_numpy(train_labels)\n",
        "\n",
        "        return train_images, train_images_torch, train_labels, train_labels_torch, terminator\n",
        "\n",
        "\n",
        "    def next_test(self, batch_size=1):\n",
        "\n",
        "        start, end = self.idx_test, self.idx_test + batch_size\n",
        "\n",
        "        terminator = False\n",
        "        if (end >= self.num_test):\n",
        "            terminator = True\n",
        "            self.test_df = shuffle(self.test_df)\n",
        "            start = 0\n",
        "            end = batch_size\n",
        "\n",
        "        self.idx_test = end\n",
        "\n",
        "        test_images = np.zeros((batch_size, self.height, self.width, self.channel))\n",
        "        test_labels = np.zeros((batch_size), dtype=int)\n",
        "        for i in range(start, end):\n",
        "            img_path = self.test_df.iloc[i]['cxr_img']\n",
        "            img_path = os.path.join(images_path, img_path)\n",
        "            test_images[i - start] = cv2.resize(cv2.imread(img_path), (256,256), interpolation = cv2.INTER_AREA)\n",
        "\n",
        "            label = self.test_df.iloc[i]['label']\n",
        "            test_labels[i - start] = 0\n",
        "            if(label in self.ab_normal_labels):\n",
        "                #abnormal is 1\n",
        "                test_labels[i - start] = 1\n",
        "\n",
        "\n",
        "        test_images = np.ndarray.astype(test_images, np.float32)\n",
        "\n",
        "        if(self.normalize):\n",
        "            min_x, max_x = test_images.min(), test_images.max()\n",
        "            test_images = (test_images - min_x) / (max_x - min_x)\n",
        "\n",
        "        test_images_torch = torch.from_numpy(np.transpose(test_images, (0, 3, 1, 2)))\n",
        "        test_labels_torch = torch.from_numpy(test_labels)\n",
        "\n",
        "        return test_images, test_images_torch, test_labels, test_labels_torch, terminator"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-eq5eyy5kA3",
        "colab_type": "text"
      },
      "source": [
        "## Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-d_7RURNP-e",
        "colab_type": "text"
      },
      "source": [
        "### The Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saB47SEgB0UG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.reshape(input.size(0), -1)\n",
        "  \n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, k_size=4):\n",
        "        super(Generator, self).__init__()\n",
        "        self.k_size = k_size\n",
        "        # enc\n",
        "        self.enc_bn1 = nn.BatchNorm2d(3)\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=self.k_size, stride=2, padding=2)\n",
        "\n",
        "        self.enc_bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=self.k_size, stride=2, padding=2)\n",
        "\n",
        "        self.enc_bn3 = nn.BatchNorm2d(128)\n",
        "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=self.k_size, stride=2, padding=2)\n",
        "\n",
        "        self.enc_bn4 = nn.BatchNorm2d(256)\n",
        "        self.conv4 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=self.k_size, stride=2, padding=2)\n",
        "\n",
        "\n",
        "        self.flat = Flatten()\n",
        "        self.en_linear1 = nn.Linear(17*17*512, 1024)\n",
        "        self.en_linear2 = nn.Linear(1024, 128)\n",
        "\n",
        "\n",
        "        #decode        \n",
        "        self.dec_linear1 = nn.Linear(128, 1024)\n",
        "        self.dec_linear2 = nn.Linear(1024,17*17*512)\n",
        "\n",
        "        self.dec_bn1 = nn.BatchNorm2d(512)\n",
        "        self.convT1 = nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=self.k_size, stride=2, padding=2, output_padding=1)\n",
        "\n",
        "        self.dec_bn2 = nn.BatchNorm2d(256)\n",
        "        self.convT2 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=self.k_size, stride=2, padding=2, output_padding=1)\n",
        "\n",
        "        self.dec_bn3 = nn.BatchNorm2d(128)\n",
        "        self.convT3 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=self.k_size, stride=2, padding=2, output_padding=1)\n",
        "\n",
        "        self.dec_bn4 = nn.BatchNorm2d(64)\n",
        "        self.convT4 = nn.ConvTranspose2d(in_channels=64, out_channels=3, kernel_size=self.k_size, stride=2, padding=2)\n",
        "\n",
        "\n",
        "\n",
        "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
        "        self.maxpool = nn.MaxPool2d(2)\n",
        "\n",
        "\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def encode(self, x):\n",
        "\n",
        "      x = self.enc_bn1(x)\n",
        "      x = self.conv1(x)\n",
        "      x = self.leaky_relu(x)\n",
        "\n",
        "      x = self.enc_bn2(x)\n",
        "      x = self.conv2(x)\n",
        "      x = self.leaky_relu(x)\n",
        "\n",
        "      x = self.enc_bn3(x)\n",
        "      x = self.conv3(x)\n",
        "      x = self.leaky_relu(x)\n",
        "      \n",
        "      x = self.enc_bn4(x)\n",
        "      x = self.conv4(x)\n",
        "      x = self.leaky_relu(x)\n",
        "\n",
        "\n",
        "      x = self.flat(x)\n",
        "      x = self.en_linear1(x)\n",
        "      x = self.leaky_relu(x)\n",
        "      x = self.en_linear2(x)\n",
        "\n",
        "      return(x)\n",
        "\n",
        "    def decode(self, x):\n",
        "      x = self.dec_linear1(x)\n",
        "      x = self.leaky_relu(x)\n",
        "      x = self.dec_linear2(x)\n",
        "\n",
        "      x = x.reshape(x.size(0), 512, 17, 17)  \n",
        "\n",
        "      x = self.dec_bn1(x)\n",
        "      x = self.convT1(x)\n",
        "      x = self.leaky_relu(x)\n",
        "\n",
        "      x = self.dec_bn2(x)\n",
        "      x = self.convT2(x)\n",
        "      x = self.leaky_relu(x)\n",
        "\n",
        "      x = self.dec_bn3(x)\n",
        "      x = self.convT3(x)\n",
        "      x = self.leaky_relu(x)\n",
        "\n",
        "      x = self.dec_bn4(x)\n",
        "      x = self.convT4(x)\n",
        "      x = self.leaky_relu(x)\n",
        "\n",
        "      return x\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encode(x)\n",
        "        x = self.decode(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9O57q8ZNTCI",
        "colab_type": "text"
      },
      "source": [
        "### The Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrNk2HyRB0UL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3*2,  64, 4, stride=2, padding=2)\n",
        "        self.conv2 = nn.Conv2d( 64, 128, 4, stride=2, padding=2)\n",
        "        self.conv3 = nn.Conv2d(128, 256, 4, stride=2, padding=2)\n",
        "        self.conv4 = nn.Conv2d(256, 512, 4, stride=2, padding=2)        \n",
        "        self.conv_bn1 = nn.BatchNorm2d(64)\n",
        "        self.conv_bn2 = nn.BatchNorm2d(128)\n",
        "        self.conv_bn3 = nn.BatchNorm2d(256)        \n",
        "        self.conv_bn4 = nn.BatchNorm2d(512) \n",
        "        self.fc = nn.Linear(512*17*17, 1)\n",
        "        self.conv_act = nn.LeakyReLU(0.2)\n",
        "        self.op_act = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # enc\n",
        "        x = self.conv_bn1(self.conv_act(self.conv1(x)))  \n",
        "        x = self.conv_bn2(self.conv_act(self.conv2(x)))    \n",
        "        x = self.conv_bn3(self.conv_act(self.conv3(x)))  \n",
        "        x = self.conv_bn4(self.conv_act(self.conv4(x)))  \n",
        "        x = self.fc(x.reshape(x.shape[0], -1))             \n",
        "        return self.op_act(x)\n",
        "    "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnN89-meB0UF",
        "colab_type": "text"
      },
      "source": [
        "## Forward-Pass, Objective Function Computations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8t61mZi9NmUc",
        "colab_type": "text"
      },
      "source": [
        "This forward-pass, objective function implements what has been proposed in the pix2pix paper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg4H3pWmB0UP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_n_get_loss(img, G, D, c=100):\n",
        "    img_hat = G(img) \n",
        "    orig_pair = torch.cat([img, img], 1)\n",
        "    hat_pair = torch.cat([img_hat, img], 1)\n",
        "    prob_orig, prob_hat = D(orig_pair), D(hat_pair).detach()\n",
        "    prob_hat_G = prob_hat.clone()\n",
        "\n",
        "    # loss_D\n",
        "    loss_D_orig = nn.BCELoss()(prob_orig, torch.ones_like(prob_orig))\n",
        "    loss_D_hat = nn.BCELoss()(prob_hat, torch.zeros_like(prob_hat))\n",
        "    loss_D = (loss_D_orig + loss_D_hat) *0.5\n",
        "    # loss_G\n",
        "    loss_G_hat = nn.BCELoss()(prob_hat, torch.ones_like(prob_hat_G))\n",
        "    loss_G_L1 = nn.L1Loss()(img_hat, img)\n",
        "    loss_G = loss_G_hat + c*loss_G_L1\n",
        "    return loss_D, loss_G, loss_D_orig, loss_D_hat, loss_G_hat, loss_G_L1\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qrb-BH0BOAER",
        "colab_type": "text"
      },
      "source": [
        "## Utilities "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bic1PRYJOC8-",
        "colab_type": "text"
      },
      "source": [
        "The following block implements a series of functions that help us with the training, testing, and logging process. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-8dksKhBQLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "def gray2rgb(gray):\n",
        "\n",
        "    rgb = np.ones((gray.shape[0], gray.shape[1], 3)).astype(np.float32)\n",
        "    rgb[:, :, 0] = gray[:, :, 0]\n",
        "    rgb[:, :, 1] = gray[:, :, 0]\n",
        "    rgb[:, :, 2] = gray[:, :, 0]\n",
        "\n",
        "    return rgb\n",
        "'''\n",
        "\n",
        "def dat2canvas(data):\n",
        "\n",
        "    numd = math.ceil(np.sqrt(data.shape[0]))\n",
        "    [dn, dh, dw, dc] = data.shape\n",
        "    canvas = np.ones((dh*numd, dw*numd, dc)).astype(np.float32)\n",
        "\n",
        "    for y in range(numd):\n",
        "        for x in range(numd):\n",
        "            try: tmp = data[x+(y*numd)]\n",
        "            except: pass\n",
        "            else: canvas[(y*dh):(y*dh)+256, (x*dw):(x*dw)+256, :] = tmp\n",
        "    #if(dc == 1):\n",
        "     #   canvas = gray2rgb(gray=canvas)\n",
        "\n",
        "    return canvas\n",
        "\n",
        "def save_img(contents, names=[\"\", \"\", \"\"], savename=\"\"):\n",
        "\n",
        "    num_cont = len(contents)\n",
        "    plt.figure(figsize=(5*num_cont+2, 5))\n",
        "\n",
        "    for i in range(num_cont):\n",
        "        plt.subplot(1,num_cont,i+1)\n",
        "        plt.title(names[i])\n",
        "        plt.imshow(dat2canvas(data=contents[i]))\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(savename)\n",
        "    plt.close()\n",
        "\n",
        "def discrete_cmap(N, base_cmap=None):\n",
        "\n",
        "    base = plt.cm.get_cmap(base_cmap)\n",
        "    color_list = base(np.linspace(0, 1, N))\n",
        "    cmap_name = base.name + str(N)\n",
        "\n",
        "    return base.from_list(cmap_name, color_list, N)\n",
        "\n",
        "# Saves a latent plot, used both for t-sne plotting and PCA plots\n",
        "def latent_plot(latent, y, n, title, savename=\"\"):\n",
        "\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    plt.scatter(latent[:, 0], latent[:, 1], c=y, \\\n",
        "        marker='o', edgecolor='none', cmap=discrete_cmap(n, 'jet'))\n",
        "    plt.colorbar(ticks=range(n))\n",
        "    plt.grid()\n",
        "    plt.tight_layout()\n",
        "    plt.title(title)\n",
        "    plt.savefig(savename)\n",
        "    plt.close()\n",
        "\n",
        "def save_graph(contents, xlabel, ylabel, savename):\n",
        "\n",
        "    np.save(savename, np.asarray(contents))\n",
        "    plt.clf()\n",
        "    plt.rcParams['font.size'] = 15\n",
        "    plt.plot(contents, color='blue', linestyle=\"-\", label=\"loss\")\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.tight_layout(pad=1, w_pad=1, h_pad=1)\n",
        "    plt.savefig(\"%s.png\" %(savename))\n",
        "    plt.close()\n",
        "\n",
        "def tens2nparr(input):\n",
        "\n",
        "    input = input.cpu()\n",
        "    output = input.detach().numpy()\n",
        "    return output\n",
        "\n",
        "# Computes Mean Squared Loss between two sets of images. This meassure is used for anomaly detection\n",
        "def restore_loss_functions(x, x_hat):\n",
        "\n",
        "    x, x_hat = x.cpu(), x_hat.cpu()\n",
        "    criterion = torch.nn.MSELoss()\n",
        "    restore_loss = criterion(x_hat, x)\n",
        "    return restore_loss\n",
        "\n",
        "def get_device():\n",
        "  device = torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\")\n",
        "\n",
        "# Trains the models, save a recounstruction plot at the beginning of each epoch\n",
        "# It is also capable of loading previously saved model parameters. \n",
        "# see *param_save_path* in the first code block\n",
        "def training(G, D, dataset, epochs, batch_size, load=False, snapshot=True):\n",
        "\n",
        "    # if a model is loaded, this number reflects the epochs of the previous training\n",
        "    epoch_offset = 0\n",
        "    if(load):\n",
        "      pre_trained_models = os.listdir(param_save_path)\n",
        "\n",
        "      param_G = os.path.join(param_save_path, pre_trained_models[-2])\n",
        "      param_D = os.path.join(param_save_path, pre_trained_models[-1])\n",
        "      print('=======')\n",
        "      print(param_D)\n",
        "      print(param_G)\n",
        "      print('=======')\n",
        "\n",
        "      G.load_state_dict(torch.load(param_G))\n",
        "      D.load_state_dict(torch.load(param_D))\n",
        "      print(\"model loaded succesffully\")\n",
        "\n",
        "      epoch_offset = int(re.findall(r'\\d+', pre_trained_models[-1])[0])\n",
        "\n",
        "      print(\"---> Model was previously trained on {}-epochs\".format(epoch_offset))\n",
        "\n",
        "\n",
        "    print(\"\\n<Training to new %d epochs (%d of minibatch size)>\" %(epochs, batch_size))\n",
        "\n",
        "    device = get_device()\n",
        "\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    iteration = 0\n",
        "\n",
        "    test_sq = 10\n",
        "    test_size = test_sq**2\n",
        "    list_recon = []\n",
        "    restore_error = 0\n",
        "\n",
        "    loss2npval = lambda loss : np.mean(loss.cpu().data.numpy()).round(4)\n",
        "    loss_names = [\"loss_D\", \"loss_G\", \"loss_D_real\", \"loss_D_fake\",  \\\n",
        "                  \"loss_G_fake\", \"loss_G_L1\"]\n",
        "    update_DnG_together = True\n",
        "    G.train()\n",
        "    D.train()\n",
        "\n",
        "    for epoch in range(epoch_offset, epoch_offset + epochs):\n",
        "\n",
        "\n",
        "        x_tr, x_tr_torch, y_tr, y_tr_torch, _ = dataset.next_train(batch_size=test_size) # Initial batch\n",
        "\n",
        "\n",
        "        x_restore = G(x_tr_torch.cuda())\n",
        "\n",
        "        x_restore = np.transpose(tens2nparr(x_restore), (0, 2, 3, 1))\n",
        "\n",
        "\n",
        "        save_img(contents=[x_tr, x_restore, (x_tr-x_restore)**2], \\\n",
        "            names=[\"Input\\n(x)\", \"Restoration\\n(x to x-hat)\", \"Difference\"], \\\n",
        "            savename=os.path.join(results_path, \"tr_restoring\", \"%d.png\" %(epoch)))\n",
        "\n",
        "\n",
        "\n",
        "        while(True):\n",
        "            if(iteration % 10 == 0):\n",
        "                print(\"->Epoch {}, Training Index {}, Latest RestoreError {}\".format(epoch, dataset.idx_train, restore_error))\n",
        "\n",
        "            x_tr, x_tr_torch, y_tr, y_tr_torch, terminator = dataset.next_train(batch_size)\n",
        "\n",
        "            x_tr_torch = x_tr_torch.cuda()\n",
        "\n",
        "            # forward and get loss\n",
        "            c = 100\n",
        "            losses = forward_n_get_loss(x_tr_torch, G, D, c=c )\n",
        "\n",
        "            update_D, update_G = (True, True) if update_DnG_together  \\\n",
        "            else ((epo+batch_No)%2!=0, (epo+batch_No)%2==0  )\n",
        "            \n",
        "            # update D\n",
        "            if update_D:\n",
        "                optimizer_D.zero_grad()\n",
        "                losses[0].backward(retain_graph=True)\n",
        "                optimizer_D.step()\n",
        "                \n",
        "            # update G\n",
        "            if update_G:\n",
        "                optimizer_G.zero_grad()\n",
        "                losses[1].backward()\n",
        "                optimizer_G.step()\n",
        "\n",
        "\n",
        "            \n",
        "\n",
        "            x_hat = G(x_tr_torch.to(device))\n",
        "\n",
        "            restore_error = restore_loss_functions(x=x_tr_torch, x_hat=x_hat)\n",
        "            list_recon.append(restore_error.item())\n",
        "\n",
        "            x_hat = np.transpose(tens2nparr(x_hat), (0, 2, 3, 1))\n",
        "\n",
        "\n",
        "            iteration += 1\n",
        "            if(terminator): break\n",
        "                \n",
        "        loss_vals = map(loss2npval, losses)\n",
        "        loss_info = dict(zip(loss_names,loss_vals))\n",
        "        print(\"[{}] {}, time_cost:\" \\\n",
        "              .format( epoch, loss_info))\n",
        "        \n",
        "        with open(OnTrain_summary_path, \"a\") as fcsv:\n",
        "          fcsv.write(\"%d,%.6f,%.6f,%.6f,%.6f,%.6f,%.6f\\n\" \\\n",
        "          %(epoch, losses[0], losses[1], losses[2], losses[3],losses[4],losses[5]))\n",
        "        \n",
        "        if(epoch % 5 == 0):\n",
        "          torch.save(G.state_dict(), param_save_path+\"/params-epoch%d-G\" %(epoch))\n",
        "          torch.save(D.state_dict(), param_save_path+\"/params-epoch%d-D\" %(epoch))\n",
        "\n",
        "          if(snapshot):\n",
        "            dataset.reset_idx()\n",
        "            snapshot_onTest(G, D, dataset, epoch)\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(\"Elapsed: \"+str(elapsed_time))\n",
        "\n",
        "# This function tests the models on the train set of the dataset and logs a bunch of plots and analytics\n",
        "def snapshot_onTest(G, D, dataset, epoch):\n",
        "\n",
        "    G_scores_normal, G_scores_abnormal = [], []\n",
        "    D_scores_normal, D_scores_abnormal = [],[]\n",
        "    latent_vectors, labels = [], []\n",
        "    G_scores = []\n",
        "    D_scores = []\n",
        "\n",
        "\n",
        "    snap_fcsv = open(snapshots_save_path+\"/01-OnTest-epoch{}-snapshot.csv\".format(epoch), \"w\")\n",
        "\n",
        "    snap_fcsv.write(\"class,G_score,D_score\\n\")\n",
        "\n",
        "\n",
        "    print(\"Test SnapShot:\")\n",
        "    while(True):\n",
        "        x, x_torch, y, y_torch, terminator = dataset.next_test(1) # y_te does not used in this prj.\n",
        "\n",
        "        x_hat = G(x_torch.cuda())\n",
        "        x_enc = tens2nparr(G.encode(x_torch.cuda()))[0]\n",
        "        G_recons_error = restore_loss_functions(x=x_torch, x_hat=x_hat)\n",
        "        x_G_score = G_recons_error.item()\n",
        "\n",
        "        pair = torch.cat([x_torch.cuda(), x_hat], 1)\n",
        "        x_D_score = D(pair.cuda()).item()\n",
        "\n",
        "\n",
        "        labels.append(y[0])\n",
        "        latent_vectors.append(x_enc)\n",
        "        G_scores.append(x_G_score)\n",
        "        D_scores.append(x_D_score)\n",
        "\n",
        "        if (y[0] == 0): \n",
        "          G_scores_normal.append(x_G_score)\n",
        "          D_scores_normal.append(x_D_score)\n",
        "        else:\n",
        "          G_scores_abnormal.append(x_G_score)\n",
        "          D_scores_abnormal.append(x_D_score)\n",
        "\n",
        "        snap_fcsv.write(\"%d,%.7f,%.7f\\n\" %(y, x_G_score, x_D_score))\n",
        "\n",
        "        if(terminator): break\n",
        "\n",
        "\n",
        "    # Saving the latent plots\n",
        "    pca = PCA(n_components=2)\n",
        "    tsne = TSNE(n_components=2)\n",
        "\n",
        "    latent_vectors, labels = np.array(latent_vectors), np.array(labels)\n",
        "\n",
        "    pca_features = pca.fit_transform(latent_vectors)\n",
        "    tsne_features = tsne.fit_transform(latent_vectors)\n",
        "\n",
        "    latent_plot(latent=pca_features, y=labels, n=dataset.num_class, title='PCA Plot-epoch%d' %(epoch),\\\n",
        "            savename=os.path.join(results_path, 'pca_latent_ontest', '%d.png' %(epoch)))\n",
        "\n",
        "    latent_plot(latent=tsne_features, y=labels, n=dataset.num_class, title='t-SNE Plot-epoch%d' %(epoch),\\\n",
        "        savename=os.path.join(results_path, 'tsne_latent_ontest', '%d.png' %(epoch)))\n",
        "    \n",
        "\n",
        "    \n",
        "    G_fpr, G_tpr, G_thresholds = metrics.roc_curve(labels, G_scores, pos_label=1)\n",
        "    G_AUC = metrics.auc(G_fpr, G_tpr)\n",
        "\n",
        "\n",
        "    D_fpr, D_tpr, D_thresholds = metrics.roc_curve(labels, D_scores, pos_label=1)\n",
        "    D_AUC = metrics.auc(D_fpr, D_tpr)\n",
        "\n",
        "    D_ins_fpr, D_ins_tpr, D_ins_thresholds = metrics.roc_curve(labels, [1 - dscore for dscore in D_scores], pos_label=1)\n",
        "    D_ins_AUC = metrics.auc(D_fpr, D_tpr)\n",
        " \n",
        "\n",
        "    G_scores_normal = np.asarray(G_scores_normal)\n",
        "    G_scores_abnormal = np.asarray(G_scores_abnormal)\n",
        "\n",
        "    D_scores_normal = np.asarray(D_scores_normal)\n",
        "    D_scores_abnormal = np.asarray(D_scores_abnormal)\n",
        "\n",
        "    G_normal_avg, G_normal_std = np.average(G_scores_normal), np.std(G_scores_normal)\n",
        "    G_abnormal_avg, G_abnormal_std = np.average(G_scores_abnormal), np.std(G_scores_abnormal)\n",
        "\n",
        "\n",
        "    D_normal_avg, D_normal_std = np.average(D_scores_normal), np.std(D_scores_normal)\n",
        "    D_abnormal_avg, D_abnormal_std = np.average(D_scores_abnormal), np.std(D_scores_abnormal)\n",
        "\n",
        "\n",
        "    print(\"EPOCH: {}\".format(epoch))\n",
        "\n",
        "    print(\" Generator Stats: \")\n",
        "    print(\"   G-Noraml  avg: %.5f, std: %.5f\" %(G_normal_avg, G_normal_std))\n",
        "    print(\"   G-Abnoraml  avg: %.5f, std: %.5f\" %(G_abnormal_avg, G_abnormal_std))\n",
        "    print('   G-AUC for epoch{}: {:.5f}'.format(epoch, G_AUC))\n",
        "\n",
        "\n",
        "    print(\" Discriminator Stats: \")\n",
        "    print(\"   D-Noraml  avg: %.5f, std: %.5f\" %(D_normal_avg, D_normal_std))\n",
        "    print(\"   D-Abnoraml  avg: %.5f, std: %.5f\" %(D_abnormal_avg, D_abnormal_std))\n",
        "    print(\"   D-AUC for epoch{}: {:.5f}\".format(epoch, D_AUC))\n",
        "\n",
        "    print(\"   D-inverse-AUC for epoch{}: {:.5f}\".format(epoch, D_ins_AUC))\n",
        "\n",
        "    with open(OnTestsnapshots_summary_path, \"a\") as fcsv:\n",
        "      fcsv.write(\"%d,%.6f,%.6f,%.6f,%.6f,%.6f,%.6f,%.6f,%.6f,%.6f,%.6f\\n\" \\\n",
        "                 %(epoch, G_normal_avg, G_abnormal_avg, D_normal_avg, D_abnormal_avg, G_normal_std, G_abnormal_std, D_normal_std, D_abnormal_std, G_AUC, D_AUC))\n",
        "      \n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2mLdbHqjbyu",
        "colab_type": "text"
      },
      "source": [
        "## Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZTgTRv2jfZp",
        "colab_type": "text"
      },
      "source": [
        "### Create instances of our neural networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "if1knsIHB0UT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "15b636dc-9bdc-48c7-9a4c-2d144d220ee4"
      },
      "source": [
        "# build model \n",
        "use_cuda = torch.cuda.is_available()\n",
        "print('use_cuda:', use_cuda)\n",
        "if use_cuda:\n",
        "    G = Generator().cuda()\n",
        "    D = Discriminator().cuda()\n",
        "else:\n",
        "    G = Generator()\n",
        "    D = Discriminator()  "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "use_cuda: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVDsycRnjj3j",
        "colab_type": "text"
      },
      "source": [
        "### Initialize the weights and bias terms by random distributoions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYzC2lBbB0UZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "39156c7d-47e7-4f99-d595-180143377c3c"
      },
      "source": [
        "# initialize weights\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Conv2d or type(m) == nn.ConvTranspose2d:\n",
        "        m.weight.data.normal_(0, 0.02)\n",
        "        m.bias.data.normal_(0, 0.02)\n",
        "G.apply(init_weights)\n",
        "D.apply(init_weights)\n",
        "print(G.conv1.weight.data.mean().mean())# close to 0.00\n",
        "print(G.conv1.weight.data.std().mean())# close to 0.02"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(-0.0002, device='cuda:0')\n",
            "tensor(0.0205, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF79JigYjs_O",
        "colab_type": "text"
      },
      "source": [
        "### Wanna know the number of parameters?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkFQ68gyATyZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1632fa16-a4be-49d8-f3c9-f2f258071b99"
      },
      "source": [
        "num_p = 0\n",
        "for idx_m, model in enumerate([G, D]):\n",
        "    for p in model.parameters():\n",
        "        num_p += p.numel()\n",
        "    #print(model)\n",
        "print(\"The number of parameters: %d\" %(num_p))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of parameters: 311875658\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUN9T9VojzMM",
        "colab_type": "text"
      },
      "source": [
        "### Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fffvgc3jB0Ue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.optim import Adam\n",
        "optimizer_G = Adam(G.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
        "optimizer_D = Adam(D.parameters(), lr=1e-4, betas=(0.5, 0.999))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AuvUEy6j3A-",
        "colab_type": "text"
      },
      "source": [
        "### Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3du-MGi-PR8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "9944e3ce-8fde-49aa-e7e9-2304943e3bfd"
      },
      "source": [
        "# an instance of the dataset object\n",
        "dataset = Dataset(n_exp=0, n_splits=3)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Initializing Dataset...\n",
            "Running experiment number 0 out of 2 ----  Train Cases: 1050 / Test Cases: 1045 Out of which 519 are COVID\n",
            "Data Summery\n",
            "Number of Training Cases: 1050\n",
            "Total Number of Test Cases: 1045, Abnormal Cases: 519\n",
            "Shape  Height: 256, Width: 256, Channel: 3\n",
            "Value  Min: 0.000, Max: 254.000\n",
            "Number of classes:  2\n",
            "Normalization: True\n",
            "(from 0.000-254.000 to 0.000-1.000)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saACGUxtFqRj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e4ac8152-971e-43a6-b685-7f5b3a228635"
      },
      "source": [
        "# training\n",
        "training(G, D, dataset, epochs=105, batch_size=30, load=True)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=======\n",
            "/content/drive/My Drive/CSC420_Project/Models/f1-AnomalyDetect/params/params-epoch85-D\n",
            "/content/drive/My Drive/CSC420_Project/Models/f1-AnomalyDetect/params/params-epoch85-G\n",
            "=======\n",
            "model loaded succesffully\n",
            "---> Model was previously trained on 85-epochs\n",
            "\n",
            "<Training to new 105 epochs (30 of minibatch size)>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 85, Training Index 100, Latest RestoreError 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2617: UserWarning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorIterator.cpp:918.)\n",
            "  ret = torch._C._nn.l1_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 85, Training Index 400, Latest RestoreError 0.0015636328607797623\n",
            "->Epoch 85, Training Index 700, Latest RestoreError 0.0013669495237991214\n",
            "->Epoch 85, Training Index 1000, Latest RestoreError 0.0013613873161375523\n",
            "[85] {'loss_D': 6.6674, 'loss_G': 2.4757, 'loss_D_real': 0.0, 'loss_D_fake': 13.3349, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0248}, time_cost:\n",
            "Test SnapShot:\n",
            "EPOCH: 85\n",
            " Generator Stats: \n",
            "   G-Noraml  avg: 0.00879, std: 0.00553\n",
            "   G-Abnoraml  avg: 0.01719, std: 0.01498\n",
            "   G-AUC for epoch85: 0.73422\n",
            " Discriminator Stats: \n",
            "   D-Noraml  avg: 0.99999, std: 0.00001\n",
            "   D-Abnoraml  avg: 0.99998, std: 0.00007\n",
            "   D-AUC for epoch85: 0.33425\n",
            "   D-inverse-AUC for epoch85: 0.33425\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 86, Training Index 340, Latest RestoreError 0.0014661785680800676\n",
            "->Epoch 86, Training Index 640, Latest RestoreError 0.0013382360339164734\n",
            "->Epoch 86, Training Index 940, Latest RestoreError 0.0014456937788054347\n",
            "[86] {'loss_D': 9.5102, 'loss_G': 2.609, 'loss_D_real': 0.0, 'loss_D_fake': 19.0203, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0261}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 87, Training Index 310, Latest RestoreError 0.0014345523668453097\n",
            "->Epoch 87, Training Index 610, Latest RestoreError 0.0014164105523377657\n",
            "->Epoch 87, Training Index 910, Latest RestoreError 0.001329816528595984\n",
            "[87] {'loss_D': 8.0167, 'loss_G': 2.6822, 'loss_D_real': 0.0, 'loss_D_fake': 16.0334, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0268}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 88, Training Index 280, Latest RestoreError 0.001253295224159956\n",
            "->Epoch 88, Training Index 580, Latest RestoreError 0.0013776002451777458\n",
            "->Epoch 88, Training Index 880, Latest RestoreError 0.001330539584159851\n",
            "[88] {'loss_D': 9.5151, 'loss_G': 2.4901, 'loss_D_real': 0.0, 'loss_D_fake': 19.0302, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0249}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 89, Training Index 250, Latest RestoreError 0.0012238265480846167\n",
            "->Epoch 89, Training Index 550, Latest RestoreError 0.001469513401389122\n",
            "->Epoch 89, Training Index 850, Latest RestoreError 0.0013815020211040974\n",
            "[89] {'loss_D': 8.377, 'loss_G': 2.4059, 'loss_D_real': 0.0, 'loss_D_fake': 16.754, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0241}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 90, Training Index 220, Latest RestoreError 0.0012981881154701114\n",
            "->Epoch 90, Training Index 520, Latest RestoreError 0.0013468301622197032\n",
            "->Epoch 90, Training Index 820, Latest RestoreError 0.001175544923171401\n",
            "[90] {'loss_D': 6.8123, 'loss_G': 2.7249, 'loss_D_real': 0.0, 'loss_D_fake': 13.6246, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0272}, time_cost:\n",
            "Test SnapShot:\n",
            "EPOCH: 90\n",
            " Generator Stats: \n",
            "   G-Noraml  avg: 0.00887, std: 0.00554\n",
            "   G-Abnoraml  avg: 0.01745, std: 0.01504\n",
            "   G-AUC for epoch90: 0.74130\n",
            " Discriminator Stats: \n",
            "   D-Noraml  avg: 1.00000, std: 0.00001\n",
            "   D-Abnoraml  avg: 0.99999, std: 0.00005\n",
            "   D-AUC for epoch90: 0.34834\n",
            "   D-inverse-AUC for epoch90: 0.34834\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 91, Training Index 160, Latest RestoreError 0.0016510483110323548\n",
            "->Epoch 91, Training Index 460, Latest RestoreError 0.001423435052856803\n",
            "->Epoch 91, Training Index 760, Latest RestoreError 0.0013811005046591163\n",
            "[91] {'loss_D': 7.011, 'loss_G': 2.8738, 'loss_D_real': 0.0, 'loss_D_fake': 14.0221, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0287}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 92, Training Index 130, Latest RestoreError 0.0013775312108919024\n",
            "->Epoch 92, Training Index 430, Latest RestoreError 0.0014200594741851091\n",
            "->Epoch 92, Training Index 730, Latest RestoreError 0.0013932037400081754\n",
            "->Epoch 92, Training Index 1030, Latest RestoreError 0.0012951933313161135\n",
            "[92] {'loss_D': 6.6876, 'loss_G': 2.59, 'loss_D_real': 0.0, 'loss_D_fake': 13.3751, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0259}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 93, Training Index 400, Latest RestoreError 0.0013712126528844237\n",
            "->Epoch 93, Training Index 700, Latest RestoreError 0.0013850765535607934\n",
            "->Epoch 93, Training Index 1000, Latest RestoreError 0.0013030299451202154\n",
            "[93] {'loss_D': 8.6971, 'loss_G': 2.5881, 'loss_D_real': 0.0, 'loss_D_fake': 17.3942, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0259}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 94, Training Index 370, Latest RestoreError 0.0013257174286991358\n",
            "->Epoch 94, Training Index 670, Latest RestoreError 0.0013388034421950579\n",
            "->Epoch 94, Training Index 970, Latest RestoreError 0.0014151891227811575\n",
            "[94] {'loss_D': 8.3855, 'loss_G': 2.479, 'loss_D_real': 0.0, 'loss_D_fake': 16.771, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0248}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 95, Training Index 340, Latest RestoreError 0.001322201918810606\n",
            "->Epoch 95, Training Index 640, Latest RestoreError 0.0014188701752573252\n",
            "->Epoch 95, Training Index 940, Latest RestoreError 0.0012640644563362002\n",
            "[95] {'loss_D': 8.5345, 'loss_G': 2.6066, 'loss_D_real': 0.0, 'loss_D_fake': 17.0689, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0261}, time_cost:\n",
            "Test SnapShot:\n",
            "EPOCH: 95\n",
            " Generator Stats: \n",
            "   G-Noraml  avg: 0.00892, std: 0.00565\n",
            "   G-Abnoraml  avg: 0.01768, std: 0.01532\n",
            "   G-AUC for epoch95: 0.73931\n",
            " Discriminator Stats: \n",
            "   D-Noraml  avg: 1.00000, std: 0.00000\n",
            "   D-Abnoraml  avg: 0.99999, std: 0.00004\n",
            "   D-AUC for epoch95: 0.33382\n",
            "   D-inverse-AUC for epoch95: 0.33382\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 96, Training Index 280, Latest RestoreError 0.0013266969472169876\n",
            "->Epoch 96, Training Index 580, Latest RestoreError 0.0013147570425644517\n",
            "->Epoch 96, Training Index 880, Latest RestoreError 0.001184412045404315\n",
            "[96] {'loss_D': 8.6145, 'loss_G': 2.7631, 'loss_D_real': 0.0, 'loss_D_fake': 17.229, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0276}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 97, Training Index 250, Latest RestoreError 0.0013420161558315158\n",
            "->Epoch 97, Training Index 550, Latest RestoreError 0.0011590715730562806\n",
            "->Epoch 97, Training Index 850, Latest RestoreError 0.0014068025629967451\n",
            "[97] {'loss_D': 8.5961, 'loss_G': 2.7306, 'loss_D_real': 0.0, 'loss_D_fake': 17.1922, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0273}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 98, Training Index 220, Latest RestoreError 0.0012057663407176733\n",
            "->Epoch 98, Training Index 520, Latest RestoreError 0.001221685903146863\n",
            "->Epoch 98, Training Index 820, Latest RestoreError 0.0012930622324347496\n",
            "[98] {'loss_D': 7.1185, 'loss_G': 2.7908, 'loss_D_real': 0.0, 'loss_D_fake': 14.2369, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0279}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 99, Training Index 190, Latest RestoreError 0.0012887284392490983\n",
            "->Epoch 99, Training Index 490, Latest RestoreError 0.0013124016113579273\n",
            "->Epoch 99, Training Index 790, Latest RestoreError 0.001331521081738174\n",
            "[99] {'loss_D': 7.0794, 'loss_G': 2.2752, 'loss_D_real': 0.0, 'loss_D_fake': 14.1588, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0228}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 100, Training Index 160, Latest RestoreError 0.0014610051875934005\n",
            "->Epoch 100, Training Index 460, Latest RestoreError 0.0012588037643581629\n",
            "->Epoch 100, Training Index 760, Latest RestoreError 0.0013744666939601302\n",
            "[100] {'loss_D': 8.3148, 'loss_G': 2.4033, 'loss_D_real': 0.0, 'loss_D_fake': 16.6296, 'loss_G_fake': 0.0, 'loss_G_L1': 0.024}, time_cost:\n",
            "Test SnapShot:\n",
            "EPOCH: 100\n",
            " Generator Stats: \n",
            "   G-Noraml  avg: 0.00858, std: 0.00551\n",
            "   G-Abnoraml  avg: 0.01691, std: 0.01454\n",
            "   G-AUC for epoch100: 0.74352\n",
            " Discriminator Stats: \n",
            "   D-Noraml  avg: 1.00000, std: 0.00001\n",
            "   D-Abnoraml  avg: 0.99999, std: 0.00005\n",
            "   D-AUC for epoch100: 0.33757\n",
            "   D-inverse-AUC for epoch100: 0.33757\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 101, Training Index 100, Latest RestoreError 0.0011584822786971927\n",
            "->Epoch 101, Training Index 400, Latest RestoreError 0.0015618364559486508\n",
            "->Epoch 101, Training Index 700, Latest RestoreError 0.001194893615320325\n",
            "->Epoch 101, Training Index 1000, Latest RestoreError 0.0012918405700474977\n",
            "[101] {'loss_D': 9.7544, 'loss_G': 2.274, 'loss_D_real': 0.0, 'loss_D_fake': 19.5089, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0227}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 102, Training Index 370, Latest RestoreError 0.001755179138854146\n",
            "->Epoch 102, Training Index 670, Latest RestoreError 0.0013586976565420628\n",
            "->Epoch 102, Training Index 970, Latest RestoreError 0.00120527483522892\n",
            "[102] {'loss_D': 8.2743, 'loss_G': 2.4411, 'loss_D_real': 0.0, 'loss_D_fake': 16.5485, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0244}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 103, Training Index 340, Latest RestoreError 0.0012160582700744271\n",
            "->Epoch 103, Training Index 640, Latest RestoreError 0.0012583931675180793\n",
            "->Epoch 103, Training Index 940, Latest RestoreError 0.001302291639149189\n",
            "[103] {'loss_D': 9.8799, 'loss_G': 2.3581, 'loss_D_real': 0.0, 'loss_D_fake': 19.7599, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0236}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 104, Training Index 310, Latest RestoreError 0.0012736691860482097\n",
            "->Epoch 104, Training Index 610, Latest RestoreError 0.0012173735303804278\n",
            "->Epoch 104, Training Index 910, Latest RestoreError 0.0010608946904540062\n",
            "[104] {'loss_D': 8.4804, 'loss_G': 2.2971, 'loss_D_real': 0.0, 'loss_D_fake': 16.9607, 'loss_G_fake': 0.0, 'loss_G_L1': 0.023}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 105, Training Index 280, Latest RestoreError 0.0011424105614423752\n",
            "->Epoch 105, Training Index 580, Latest RestoreError 0.001143887173384428\n",
            "->Epoch 105, Training Index 880, Latest RestoreError 0.0011889225570484996\n",
            "[105] {'loss_D': 9.9568, 'loss_G': 2.3746, 'loss_D_real': 0.0, 'loss_D_fake': 19.9136, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0237}, time_cost:\n",
            "Test SnapShot:\n",
            "EPOCH: 105\n",
            " Generator Stats: \n",
            "   G-Noraml  avg: 0.00866, std: 0.00564\n",
            "   G-Abnoraml  avg: 0.01717, std: 0.01472\n",
            "   G-AUC for epoch105: 0.74800\n",
            " Discriminator Stats: \n",
            "   D-Noraml  avg: 0.99999, std: 0.00001\n",
            "   D-Abnoraml  avg: 0.99998, std: 0.00011\n",
            "   D-AUC for epoch105: 0.35318\n",
            "   D-inverse-AUC for epoch105: 0.35318\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 106, Training Index 220, Latest RestoreError 0.0011774457525461912\n",
            "->Epoch 106, Training Index 520, Latest RestoreError 0.0012344890274107456\n",
            "->Epoch 106, Training Index 820, Latest RestoreError 0.0012639608466997743\n",
            "[106] {'loss_D': 10.0608, 'loss_G': 2.2128, 'loss_D_real': 0.0, 'loss_D_fake': 20.1216, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0221}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 107, Training Index 190, Latest RestoreError 0.001212265226058662\n",
            "->Epoch 107, Training Index 490, Latest RestoreError 0.0011165215400978923\n",
            "->Epoch 107, Training Index 790, Latest RestoreError 0.0012228109408169985\n",
            "[107] {'loss_D': 8.4373, 'loss_G': 2.5227, 'loss_D_real': 0.0, 'loss_D_fake': 16.8745, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0252}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 108, Training Index 160, Latest RestoreError 0.0013097996124997735\n",
            "->Epoch 108, Training Index 460, Latest RestoreError 0.0011743380455300212\n",
            "->Epoch 108, Training Index 760, Latest RestoreError 0.0011466960422694683\n",
            "[108] {'loss_D': 8.3194, 'loss_G': 2.6423, 'loss_D_real': 0.0, 'loss_D_fake': 16.6387, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0264}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 109, Training Index 130, Latest RestoreError 0.0014988196780905128\n",
            "->Epoch 109, Training Index 430, Latest RestoreError 0.0011109710903838277\n",
            "->Epoch 109, Training Index 730, Latest RestoreError 0.0012273333268240094\n",
            "->Epoch 109, Training Index 1030, Latest RestoreError 0.0013676290400326252\n",
            "[109] {'loss_D': 6.4417, 'loss_G': 2.7176, 'loss_D_real': 0.0, 'loss_D_fake': 12.8834, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0272}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 110, Training Index 400, Latest RestoreError 0.0012148693203926086\n",
            "->Epoch 110, Training Index 700, Latest RestoreError 0.001238291966728866\n",
            "->Epoch 110, Training Index 1000, Latest RestoreError 0.0010783032048493624\n",
            "[110] {'loss_D': 6.7267, 'loss_G': 2.6302, 'loss_D_real': 0.0, 'loss_D_fake': 13.4534, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0263}, time_cost:\n",
            "Test SnapShot:\n",
            "EPOCH: 110\n",
            " Generator Stats: \n",
            "   G-Noraml  avg: 0.00887, std: 0.00553\n",
            "   G-Abnoraml  avg: 0.01755, std: 0.01491\n",
            "   G-AUC for epoch110: 0.74680\n",
            " Discriminator Stats: \n",
            "   D-Noraml  avg: 0.99999, std: 0.00003\n",
            "   D-Abnoraml  avg: 0.99996, std: 0.00017\n",
            "   D-AUC for epoch110: 0.33029\n",
            "   D-inverse-AUC for epoch110: 0.33029\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 111, Training Index 340, Latest RestoreError 0.0013180735986679792\n",
            "->Epoch 111, Training Index 640, Latest RestoreError 0.001171985873952508\n",
            "->Epoch 111, Training Index 940, Latest RestoreError 0.0012016849359497428\n",
            "[111] {'loss_D': 8.3343, 'loss_G': 2.2831, 'loss_D_real': 0.0, 'loss_D_fake': 16.6685, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0228}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 112, Training Index 310, Latest RestoreError 0.0011312048882246017\n",
            "->Epoch 112, Training Index 610, Latest RestoreError 0.0011189947836101055\n",
            "->Epoch 112, Training Index 910, Latest RestoreError 0.001476824632845819\n",
            "[112] {'loss_D': 6.6393, 'loss_G': 2.5013, 'loss_D_real': 0.0, 'loss_D_fake': 13.2787, 'loss_G_fake': 0.0, 'loss_G_L1': 0.025}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 113, Training Index 280, Latest RestoreError 0.001151576521806419\n",
            "->Epoch 113, Training Index 580, Latest RestoreError 0.0010759937576949596\n",
            "->Epoch 113, Training Index 880, Latest RestoreError 0.0010933834128081799\n",
            "[113] {'loss_D': 9.5734, 'loss_G': 2.261, 'loss_D_real': 0.0, 'loss_D_fake': 19.1468, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0226}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 114, Training Index 250, Latest RestoreError 0.0012051687808707356\n",
            "->Epoch 114, Training Index 550, Latest RestoreError 0.0011088007595390081\n",
            "->Epoch 114, Training Index 850, Latest RestoreError 0.001073829596862197\n",
            "[114] {'loss_D': 7.9971, 'loss_G': 2.3479, 'loss_D_real': 0.0, 'loss_D_fake': 15.9943, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0235}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 115, Training Index 220, Latest RestoreError 0.001112467492930591\n",
            "->Epoch 115, Training Index 520, Latest RestoreError 0.0011681142495945096\n",
            "->Epoch 115, Training Index 820, Latest RestoreError 0.0010430775582790375\n",
            "[115] {'loss_D': 6.628, 'loss_G': 2.4255, 'loss_D_real': 0.0, 'loss_D_fake': 13.256, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0243}, time_cost:\n",
            "Test SnapShot:\n",
            "EPOCH: 115\n",
            " Generator Stats: \n",
            "   G-Noraml  avg: 0.00867, std: 0.00543\n",
            "   G-Abnoraml  avg: 0.01711, std: 0.01469\n",
            "   G-AUC for epoch115: 0.74395\n",
            " Discriminator Stats: \n",
            "   D-Noraml  avg: 0.99997, std: 0.00013\n",
            "   D-Abnoraml  avg: 0.99992, std: 0.00033\n",
            "   D-AUC for epoch115: 0.34226\n",
            "   D-inverse-AUC for epoch115: 0.34226\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 116, Training Index 160, Latest RestoreError 0.0011827591806650162\n",
            "->Epoch 116, Training Index 460, Latest RestoreError 0.001166997360996902\n",
            "->Epoch 116, Training Index 760, Latest RestoreError 0.001255699316971004\n",
            "[116] {'loss_D': 6.8534, 'loss_G': 2.3559, 'loss_D_real': 0.0, 'loss_D_fake': 13.7068, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0236}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 117, Training Index 130, Latest RestoreError 0.0011241555912420154\n",
            "->Epoch 117, Training Index 430, Latest RestoreError 0.001175454119220376\n",
            "->Epoch 117, Training Index 730, Latest RestoreError 0.0011161442380398512\n",
            "->Epoch 117, Training Index 1030, Latest RestoreError 0.000980044947937131\n",
            "[117] {'loss_D': 6.8268, 'loss_G': 2.4571, 'loss_D_real': 0.0, 'loss_D_fake': 13.6536, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0246}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 118, Training Index 400, Latest RestoreError 0.0013041435740888119\n",
            "->Epoch 118, Training Index 700, Latest RestoreError 0.0012067453935742378\n",
            "->Epoch 118, Training Index 1000, Latest RestoreError 0.001057950546965003\n",
            "[118] {'loss_D': 6.4661, 'loss_G': 2.2659, 'loss_D_real': 0.0, 'loss_D_fake': 12.9321, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0227}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 119, Training Index 370, Latest RestoreError 0.0013005883665755391\n",
            "->Epoch 119, Training Index 670, Latest RestoreError 0.0010302939917892218\n",
            "->Epoch 119, Training Index 970, Latest RestoreError 0.0011050307657569647\n",
            "[119] {'loss_D': 7.0533, 'loss_G': 2.2038, 'loss_D_real': 0.0, 'loss_D_fake': 14.1066, 'loss_G_fake': 0.0, 'loss_G_L1': 0.022}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 120, Training Index 340, Latest RestoreError 0.0010529988212510943\n",
            "->Epoch 120, Training Index 640, Latest RestoreError 0.0011208878131583333\n",
            "->Epoch 120, Training Index 940, Latest RestoreError 0.001109004719182849\n",
            "[120] {'loss_D': 6.7558, 'loss_G': 2.1624, 'loss_D_real': 0.0, 'loss_D_fake': 13.5116, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0216}, time_cost:\n",
            "Test SnapShot:\n",
            "EPOCH: 120\n",
            " Generator Stats: \n",
            "   G-Noraml  avg: 0.00867, std: 0.00541\n",
            "   G-Abnoraml  avg: 0.01705, std: 0.01449\n",
            "   G-AUC for epoch120: 0.74365\n",
            " Discriminator Stats: \n",
            "   D-Noraml  avg: 0.99994, std: 0.00024\n",
            "   D-Abnoraml  avg: 0.99987, std: 0.00049\n",
            "   D-AUC for epoch120: 0.34449\n",
            "   D-inverse-AUC for epoch120: 0.34449\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 121, Training Index 280, Latest RestoreError 0.001210576156154275\n",
            "->Epoch 121, Training Index 580, Latest RestoreError 0.0011728308163583279\n",
            "->Epoch 121, Training Index 880, Latest RestoreError 0.001148222596384585\n",
            "[121] {'loss_D': 6.4505, 'loss_G': 2.3339, 'loss_D_real': 0.0, 'loss_D_fake': 12.901, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0233}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 122, Training Index 250, Latest RestoreError 0.001115518156439066\n",
            "->Epoch 122, Training Index 550, Latest RestoreError 0.0010193940252065659\n",
            "->Epoch 122, Training Index 850, Latest RestoreError 0.001300662406720221\n",
            "[122] {'loss_D': 6.3232, 'loss_G': 2.3813, 'loss_D_real': 0.0, 'loss_D_fake': 12.6464, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0238}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 123, Training Index 220, Latest RestoreError 0.0011792120058089495\n",
            "->Epoch 123, Training Index 520, Latest RestoreError 0.0011476700892671943\n",
            "->Epoch 123, Training Index 820, Latest RestoreError 0.0010519541101530194\n",
            "[123] {'loss_D': 6.6703, 'loss_G': 2.1887, 'loss_D_real': 0.0, 'loss_D_fake': 13.3406, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0219}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 124, Training Index 190, Latest RestoreError 0.0011752786813303828\n",
            "->Epoch 124, Training Index 490, Latest RestoreError 0.001062096212990582\n",
            "->Epoch 124, Training Index 790, Latest RestoreError 0.0010481501230970025\n",
            "[124] {'loss_D': 6.3549, 'loss_G': 2.2472, 'loss_D_real': 0.0, 'loss_D_fake': 12.7097, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0225}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 125, Training Index 160, Latest RestoreError 0.0010116834891960025\n",
            "->Epoch 125, Training Index 460, Latest RestoreError 0.0011328422697260976\n",
            "->Epoch 125, Training Index 760, Latest RestoreError 0.0013218658277764916\n",
            "[125] {'loss_D': 6.523, 'loss_G': 2.8411, 'loss_D_real': 0.0, 'loss_D_fake': 13.0459, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0284}, time_cost:\n",
            "Test SnapShot:\n",
            "EPOCH: 125\n",
            " Generator Stats: \n",
            "   G-Noraml  avg: 0.00869, std: 0.00543\n",
            "   G-Abnoraml  avg: 0.01705, std: 0.01464\n",
            "   G-AUC for epoch125: 0.73736\n",
            " Discriminator Stats: \n",
            "   D-Noraml  avg: 0.99994, std: 0.00023\n",
            "   D-Abnoraml  avg: 0.99986, std: 0.00053\n",
            "   D-AUC for epoch125: 0.33961\n",
            "   D-inverse-AUC for epoch125: 0.33961\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 126, Training Index 100, Latest RestoreError 0.001317101763561368\n",
            "->Epoch 126, Training Index 400, Latest RestoreError 0.0010276089888066053\n",
            "->Epoch 126, Training Index 700, Latest RestoreError 0.0011070682667195797\n",
            "->Epoch 126, Training Index 1000, Latest RestoreError 0.0012105951318517327\n",
            "[126] {'loss_D': 6.1692, 'loss_G': 2.3768, 'loss_D_real': 0.0, 'loss_D_fake': 12.3385, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0238}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 127, Training Index 370, Latest RestoreError 0.0010048828553408384\n",
            "->Epoch 127, Training Index 670, Latest RestoreError 0.0012183673679828644\n",
            "->Epoch 127, Training Index 970, Latest RestoreError 0.0010379671584814787\n",
            "[127] {'loss_D': 6.3909, 'loss_G': 2.5777, 'loss_D_real': 0.0, 'loss_D_fake': 12.7817, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0258}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 128, Training Index 340, Latest RestoreError 0.0012328943703323603\n",
            "->Epoch 128, Training Index 640, Latest RestoreError 0.0010559570509940386\n",
            "->Epoch 128, Training Index 940, Latest RestoreError 0.0011084683937951922\n",
            "[128] {'loss_D': 6.4815, 'loss_G': 2.3293, 'loss_D_real': 0.0, 'loss_D_fake': 12.9629, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0233}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 129, Training Index 310, Latest RestoreError 0.001114172744564712\n",
            "->Epoch 129, Training Index 610, Latest RestoreError 0.001233040471561253\n",
            "->Epoch 129, Training Index 910, Latest RestoreError 0.0010645396541804075\n",
            "[129] {'loss_D': 6.5745, 'loss_G': 2.6076, 'loss_D_real': 0.0, 'loss_D_fake': 13.1489, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0261}, time_cost:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 130, Training Index 280, Latest RestoreError 0.001047296216711402\n",
            "->Epoch 130, Training Index 580, Latest RestoreError 0.001008387771435082\n",
            "->Epoch 130, Training Index 880, Latest RestoreError 0.0010093493619933724\n",
            "[130] {'loss_D': 6.655, 'loss_G': 2.2389, 'loss_D_real': 0.0, 'loss_D_fake': 13.3099, 'loss_G_fake': 0.0, 'loss_G_L1': 0.0224}, time_cost:\n",
            "Test SnapShot:\n",
            "EPOCH: 130\n",
            " Generator Stats: \n",
            "   G-Noraml  avg: 0.00849, std: 0.00534\n",
            "   G-Abnoraml  avg: 0.01692, std: 0.01446\n",
            "   G-AUC for epoch130: 0.74852\n",
            " Discriminator Stats: \n",
            "   D-Noraml  avg: 0.99987, std: 0.00097\n",
            "   D-Abnoraml  avg: 0.99979, std: 0.00071\n",
            "   D-AUC for epoch130: 0.33482\n",
            "   D-inverse-AUC for epoch130: 0.33482\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "->Epoch 131, Training Index 220, Latest RestoreError 0.0010980351362377405\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-a635828893ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m105\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-06844bfb8eac>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(G, D, dataset, epochs, batch_size, load, snapshot)\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mupdate_G\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0moptimizer_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m                 \u001b[0moptimizer_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Godnz2xB0Ur",
        "colab_type": "raw"
      },
      "source": [
        "# train!\n",
        "G.load_state_dict(torch.load(\"model/G_0035\"))\n",
        "D.load_state_dict(torch.load(\"model/D_0035\"))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqFAgylrB0Uw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi -l 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdLeHzCrJtxo",
        "colab_type": "text"
      },
      "source": [
        "# Works Cited"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXcSBEy8J0pf",
        "colab_type": "text"
      },
      "source": [
        "[1] Zhang , Jianpeng. et al, \"Viral Pneumonia Screening on Chest X-ray Images Using Confidence-Aware Anomaly Detection,\" arXiv:2003.12338, 2020.\n"
      ]
    }
  ]
}